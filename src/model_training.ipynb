{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/d4data/biomedical-ner-all\n",
    "https://huggingface.co/datasets/singh-aditya/MACCROBAT_biomedical_ner\n",
    "\n",
    "https://www.freecodecamp.org/news/getting-started-with-ner-models-using-huggingface/\n",
    "https://medium.com/@minhle_0210/pos-tagging-medical-ner-ffcdaef7a7b3\n",
    "https://github.com/dreji18/Bio-Epidemiology-NER\n",
    "\n",
    "https://huggingface.co/distilbert/distilbert-base-uncased\n",
    "https://huggingface.co/google-bert/bert-base-uncased\n",
    "https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT\n",
    "https://huggingface.co/Charangan/MedBERT\n",
    "\n",
    "https://wandb.ai/jack-morris/david-vs-goliath/reports/Does-Model-Size-Matter-A-Comparison-of-BERT-and-DistilBERT--VmlldzoxMDUxNzU#:~:text=The%20BERT%20authors%20recommend%20fine,5e%2D5%2C%203e%2D5\n",
    "https://datascience.stackexchange.com/questions/64583/what-are-the-good-parameter-ranges-for-bert-hyperparameters-while-finetuning-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'Sign_symptom', 'score': 0.9999311, 'word': 'palpitations', 'start': 38, 'end': 50}, {'entity_group': 'Clinical_event', 'score': 0.99975544, 'word': 'follow', 'start': 54, 'end': 60}, {'entity_group': 'Date', 'score': 0.999867, 'word': '6 months after', 'start': 64, 'end': 78}]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n",
    "\n",
    "pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0, aggregation_strategy=\"max\")  # device=0 (gpu)\n",
    "\n",
    "text = \"\"\"The patient reported no recurrence of palpitations at follow-up 6 months after the ablation.\"\"\"\n",
    "\n",
    "out = pipe(text)\n",
    "print(out)\n",
    "\n",
    "spans = []\n",
    "\n",
    "for row in out:\n",
    "    spans.append((row[\"start\"], row[\"end\"], row[\"entity_group\"]))\n",
    "\n",
    "# show_span_ascii_markup(text, spans)\n",
    "show_span_box_markup(text, spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\CodeProjects\\GitHub\\AAI3003_NLP_MedicalNER\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline, AutoTokenizer, DataCollatorForTokenClassification, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers.utils.logging import set_verbosity_error\n",
    "\n",
    "from ipymarkup import show_span_ascii_markup, show_span_box_markup\n",
    "\n",
    "import mrb_ner_config\n",
    "from mrb_ner_dataset import MRBNERDataset\n",
    "from mrb_ner_evaluator import MRBNEREvaluator\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"singh-aditya/MACCROBAT_biomedical_ner\"\n",
    "data = load_dataset(DATA_PATH)\n",
    "# print(dataset.data[\"train\"][\"tokens\"][0])\n",
    "# print(dataset.data[\"train\"][\"ner_labels\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = data[\"train\"].features[\"ner_labels\"].feature.names\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "\n",
    "for idx, label in enumerate(label_names):\n",
    "    id2label[idx] = label\n",
    "    label2id[label] = idx\n",
    "\n",
    "# print(len(label2id))\n",
    "# print(len(id2label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = {}\n",
    "data_splits[\"train\"], data_splits[\"val\"], data_splits[\"test\"]  = random_split(data[\"train\"], [0.7, 0.15, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MRBNEREvaluator(metric=\"seqeval\", id2label=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "MODELS = [\n",
    "    {\n",
    "        \"name\": \"distilbert-base-uncased\",\n",
    "        \"path\": \"distilbert/distilbert-base-uncased\",\n",
    "        \"save_trainer\": None,\n",
    "        \"test_metrics\": None,\n",
    "        \"param\": None\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"biobert\",\n",
    "        \"path\": \"dmis-lab/biobert-v1.1\",\n",
    "        \"save_trainer\": None,\n",
    "        \"test_metrics\": None,\n",
    "        \"param\": None\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"bio-clinical-bert\",\n",
    "        \"path\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "        \"save_trainer\": None,\n",
    "        \"test_metrics\": None,\n",
    "        \"param\": None\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"medbert\",\n",
    "        \"path\": \"Charangan/MedBERT\",\n",
    "        \"save_trainer\": None,\n",
    "        \"test_metrics\": None,\n",
    "        \"param\": None\n",
    "    }\n",
    "]\n",
    "LRATES = [5e-5, 4e-5, 3e-5, 2e-5]\n",
    "WDECAY = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Training Model (Model:distilbert-base-uncased, Lr:5e-05) ----------------------\n",
      "{'eval_loss': 2.4831795692443848, 'eval_overall_precision': 0.0, 'eval_overall_recall': 0.0, 'eval_overall_f1': 0.0, 'eval_overall_accuracy': 0.0, 'eval_runtime': 0.536, 'eval_samples_per_second': 55.97, 'eval_steps_per_second': 7.463, 'epoch': 1.0}\n",
      "{'train_runtime': 7.416, 'train_samples_per_second': 18.878, 'train_steps_per_second': 2.427, 'train_loss': 2.9876526726616754, 'epoch': 1.0}\n",
      "Updating best accuracy: None -> 0.0\n",
      "---------------------- Training Model (Model:distilbert-base-uncased, Lr:4e-05) ----------------------\n",
      "{'eval_loss': 2.4635941982269287, 'eval_overall_precision': 0.0, 'eval_overall_recall': 0.0, 'eval_overall_f1': 0.0, 'eval_overall_accuracy': 0.0, 'eval_runtime': 0.541, 'eval_samples_per_second': 55.453, 'eval_steps_per_second': 7.394, 'epoch': 1.0}\n",
      "{'train_runtime': 6.71, 'train_samples_per_second': 20.864, 'train_steps_per_second': 2.683, 'train_loss': 2.9040739271375866, 'epoch': 1.0}\n",
      "---------------------- Training Model (Model:distilbert-base-uncased, Lr:3e-05) ----------------------\n",
      "{'eval_loss': 2.5889434814453125, 'eval_overall_precision': 0.0, 'eval_overall_recall': 0.0, 'eval_overall_f1': 0.0, 'eval_overall_accuracy': 0.0, 'eval_runtime': 0.548, 'eval_samples_per_second': 54.744, 'eval_steps_per_second': 7.299, 'epoch': 1.0}\n",
      "{'train_runtime': 6.921, 'train_samples_per_second': 20.228, 'train_steps_per_second': 2.601, 'train_loss': 3.0286212497287326, 'epoch': 1.0}\n",
      "---------------------- Training Model (Model:distilbert-base-uncased, Lr:2e-05) ----------------------\n",
      "{'eval_loss': 2.7778546810150146, 'eval_overall_precision': 0.0, 'eval_overall_recall': 0.0, 'eval_overall_f1': 0.0, 'eval_overall_accuracy': 0.0, 'eval_runtime': 0.553, 'eval_samples_per_second': 54.25, 'eval_steps_per_second': 7.233, 'epoch': 1.0}\n",
      "{'train_runtime': 6.709, 'train_samples_per_second': 20.867, 'train_steps_per_second': 2.683, 'train_loss': 3.22194586859809, 'epoch': 1.0}\n",
      "{'name': 'distilbert-base-uncased', 'path': 'distilbert/distilbert-base-uncased', 'save_trainer': <transformers.trainer.Trainer object at 0x00000208ED07BEE0>, 'test_metrics': {'test_loss': 2.5951497554779053, 'test_overall_precision': 0.0, 'test_overall_recall': 0.0, 'test_overall_f1': 0.0, 'test_overall_accuracy': 0.0, 'test_runtime': 0.512, 'test_samples_per_second': 58.594, 'test_steps_per_second': 7.813}, 'param': 5e-05}\n",
      "---------------------- Training Model (Model:biobert, Lr:5e-05) ----------------------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for m in MODELS:\n",
    "    for lr in LRATES: \n",
    "        print(f\"\\n---------------------- Training Model (Model:{m['name']}, Lr:{lr}) ----------------------\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(m[\"path\"])\n",
    "        data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "        model = AutoModelForTokenClassification.from_pretrained(\n",
    "            pretrained_model_name_or_path=m[\"path\"],\n",
    "            label2id=label2id,\n",
    "            id2label=id2label,\n",
    "            ignore_mismatched_sizes=True,\n",
    "            num_labels=len(label2id)\n",
    "        )\n",
    "\n",
    "        datasets = {}\n",
    "        datasets[\"train\"] = MRBNERDataset(data=data_splits[\"train\"], tokenizer=tokenizer, id2label=id2label, label2id=label2id, max_len=512)\n",
    "        datasets[\"val\"] = MRBNERDataset(data=data_splits[\"val\"], tokenizer=tokenizer, id2label=id2label, label2id=label2id, max_len=512)\n",
    "        datasets[\"test\"] = MRBNERDataset(data=data_splits[\"test\"], tokenizer=tokenizer, id2label=id2label, label2id=label2id, max_len=512)\n",
    "\n",
    "        torch.cuda.empty_cache() if DEVICE == \"cuda\" else None\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f\"../output/{m['name']}/{lr}/cp\",\n",
    "            overwrite_output_dir=True,\n",
    "            per_device_train_batch_size=BATCH_SIZE,\n",
    "            per_device_eval_batch_size=BATCH_SIZE,\n",
    "            num_train_epochs=EPOCHS,\n",
    "            learning_rate=lr,\n",
    "            weight_decay=WDECAY,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=datasets[\"train\"],\n",
    "            eval_dataset=datasets[\"val\"],\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=evaluator.compute_metrics\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        predictions, _, metrics = trainer.predict(datasets[\"test\"])\n",
    "\n",
    "        if m[\"test_metrics\"] == None or m[\"test_metrics\"][\"test_overall_accuracy\"] < metrics[\"test_overall_accuracy\"]:\n",
    "            best_accuracy = m['test_metrics']['test_overall_accuracy'] if m['test_metrics'] else None\n",
    "            print(f\"Updating best accuracy: {best_accuracy} -> {metrics['test_overall_accuracy']}\")\n",
    "            m[\"save_trainer\"] = trainer\n",
    "            m[\"test_metrics\"] = metrics\n",
    "            m[\"param\"] = lr\n",
    "\n",
    "    print(\"Saved Model Metrics:\")\n",
    "    for key, value in m[\"test_metrics\"].items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    m[\"save_trainer\"].save_model(f\"../output/{m['name']}/save_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'SIGN_SYMPTOM', 'score': 0.49153978, 'word': 'recurrence', 'start': 24, 'end': 34}, {'entity_group': 'SIGN_SYMPTOM', 'score': 0.702181, 'word': 'palpitations', 'start': 38, 'end': 50}, {'entity_group': 'DATE', 'score': 0.46011654, 'word': '6 months after', 'start': 64, 'end': 78}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">The patient reported no <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\">recurrence<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">SIGN_SYMPTOM</span></span> of <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\">palpitations<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">SIGN_SYMPTOM</span></span> at follow-up <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">6 months after<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">DATE</span></span> the ablation.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0, aggregation_strategy=\"max\")  # device=0 (gpu)\n",
    "text = \"\"\"The patient reported no recurrence of palpitations at follow-up 6 months after the ablation.\"\"\"\n",
    "\n",
    "out = pipe(text)\n",
    "print(out)\n",
    "\n",
    "spans = []\n",
    "\n",
    "for row in out:\n",
    "    spans.append((row[\"start\"], row[\"end\"], row[\"entity_group\"]))\n",
    "\n",
    "show_span_box_markup(text, spans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
